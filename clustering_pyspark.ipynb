{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identificação de hackers do sistema de uma empresa\n",
    "\n",
    "## Descrição do problema\n",
    "\n",
    "Uma empresa sofreu ataques hacker em seu sistema e está tentando identificar os hackers envolvidos. Ela já verificou que pelo menos 2 indivíduos participaram dos ataques e agora está investigando a participação de um terceiro. \n",
    "\n",
    "O objetivo desse projeto e investigar se 2 ou 3 hackers foram os responsáveis pelos ataques. A empresa possuí dados de cada sessão de hackeamento. As informações são as seguintes:\n",
    "\n",
    "    - Tempo de conexão em minutos\n",
    "    - Quantidade de dados transferidos durante a sessão \n",
    "    - Uso do Kali Linux (Sim ou Não)\n",
    "    - Número de servidores corrompidos\n",
    "    - Número de páginas acessadas ilegalmente\n",
    "    - Localidade do ataque \n",
    "    - Velocidade de digitação.\n",
    "    \n",
    "Essa investigação pode ser realizada utilizando algorítmos de clusterização de Machine Learning. \n",
    "\n",
    "Uma outra informação crucial na resolução dessa investigação é que os hackers dividem o número de ataques de forma igual entre os participantes. Dessa forma se ocorreram 100 ataques e 2 indivíduos foram envolvidos deve-se ter 50 ataques de cada. Por outro lado, se 3 pessoas participaram cada indivíduo efetuou aproximadamente 33 ataques. \n",
    "\n",
    "Esse problema é solucionado abaixo utilizando-se o método K-means de clusterização no pyspark. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregamento dos dados e pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('clustering').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carrega os dados\n",
    "data = spark.read.csv('hack_data.csv', header = True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(Session_Connection_Time=8.0, Bytes Transferred=391.09, Kali_Trace_Used=1, Servers_Corrupted=2.96, Pages_Corrupted=7.0, Location='Slovenia', WPM_Typing_Speed=72.37)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Session_Connection_Time: double (nullable = true)\n",
      " |-- Bytes Transferred: double (nullable = true)\n",
      " |-- Kali_Trace_Used: integer (nullable = true)\n",
      " |-- Servers_Corrupted: double (nullable = true)\n",
      " |-- Pages_Corrupted: double (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- WPM_Typing_Speed: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clusterização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Session_Connection_Time',\n",
       " 'Bytes Transferred',\n",
       " 'Kali_Trace_Used',\n",
       " 'Servers_Corrupted',\n",
       " 'Pages_Corrupted',\n",
       " 'Location',\n",
       " 'WPM_Typing_Speed']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A localidade não será considerada na análise pois os ataques usualmente utilizam de VPNs e portanto essa informação não é útil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agrupa as variáveis que serão utilizadas na análise\n",
    "assembler = VectorAssembler(inputCols=['Session_Connection_Time','Bytes Transferred','Kali_Trace_Used'\n",
    "                            ,'Servers_Corrupted','Pages_Corrupted','WPM_Typing_Speed'], outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = assembler.transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O método K-means é baseado no cálculo de distâncias no espaço das variáveis. Portanto, para utilizá-lo as variáveis devem estar todas em escalas comparáveis. \n",
    "\n",
    "Abaixo a normalização das variáveis é realizada utilizando o pacote StandardScaler do pyspark. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler(inputCol='features', outputCol='scaled_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normaliza os dados\n",
    "scaler_model = scaler.fit(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = scaler_model.transform(final_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para se identificar se 2 ou 3 hackers atuaram nos ataques a clusterização é realizada com 2 e 3 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans2 = KMeans(featuresCol='scaled_features', k = 2)\n",
    "kmeans3 = KMeans(featuresCol='scaled_features', k = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 49:=========================================>            (155 + 4) / 200]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "model2 = kmeans2.fit(final_data)\n",
    "model3 = kmeans3.fit(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2 = model2.transform(final_data)\n",
    "predictions3 = model3.transform(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|prediction|\n",
      "+----------+\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "|         0|\n",
      "+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+----------+\n",
      "|prediction|\n",
      "+----------+\n",
      "|         2|\n",
      "|         2|\n",
      "|         2|\n",
      "|         2|\n",
      "|         2|\n",
      "+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions2.select('prediction').show(5)\n",
    "predictions3.select('prediction').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import ClusteringEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcula o coeficiente de silhueta nos dois casos\n",
    "evaluator = ClusteringEvaluator()\n",
    "silhouette2 = evaluator.evaluate(predictions2)\n",
    "silhouette3 = evaluator.evaluate(predictions3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A coeficiente de silhueta quando tem-se 2 clusters é igual a 0.67\n",
      "A coeficiente de silhueta quando tem-se 3 clusters é igual a 0.30\n"
     ]
    }
   ],
   "source": [
    "print('A coeficiente de silhueta quando tem-se 2 clusters é igual a {:.2f}'.format(silhouette2))\n",
    "print('A coeficiente de silhueta quando tem-se 3 clusters é igual a {:.2f}'.format(silhouette3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os valores do coeficiente de silhueta já indicam que os ataques são melhor agrupados em 2 clusters e, portanto, apenas 2 indivíduos estariam envolvidos nos ataques.\n",
    "\n",
    "Para confirmar esse resultado podemos verificar o número de ataques nos 2 casos, pois sabe-se que os hackers dividem igualmente os ataques. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "|         1|  167|\n",
      "|         0|  167|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions2.groupBy('prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "|         1|   79|\n",
      "|         2|  167|\n",
      "|         0|   88|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions3.groupBy('prediction').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando os ataques são dividos em 3 clusters o número de ataques associados a cada cluster é muito desigual.\n",
    "\n",
    "Com 2 clusters um mesmo número de ataques é associado para cada. Dessa forma é bastante provável que apenas 2 hackers participaram dos ataques."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
